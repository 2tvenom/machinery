{"name":"Machinery","tagline":"Machinery is an asynchronous task queue/job queue based on distributed message passing.","body":"[1]: https://raw.githubusercontent.com/RichardKnop/assets/master/machinery/example_worker.png\r\n[2]: https://raw.githubusercontent.com/RichardKnop/assets/master/machinery/example_worker_receives_tasks.png\r\n\r\n[![GoDoc](https://img.shields.io/badge/godoc-reference-blue.svg \"GoDoc\")](http://godoc.org/github.com/RichardKnop/machinery/v1)\r\n[![Build Status](https://travis-ci.org/RichardKnop/machinery.svg?branch=master \"Build Status\")](https://travis-ci.org/RichardKnop/machinery)\r\n\r\n# Machinery\r\n\r\nMachinery is an asynchronous task queue/job queue based on distributed message passing.\r\n\r\nSo called tasks (or jobs if you like) are executed concurrently either by many workers on many servers or multiple worker processes on a single server using Golang's goroutines.\r\n\r\nThis is an early stage project so far. Feel free to contribute.\r\n\r\n- [First Steps](http://richardknop.github.io/machinery/#first-steps)\r\n- [Configuration](http://richardknop.github.io/machinery/#configuration)\r\n- [Server](http://richardknop.github.io/machinery/#server)\r\n- [Workers](http://richardknop.github.io/machinery/#workers)\r\n- [Tasks](http://richardknop.github.io/machinery/#tasks)\r\n    - [Registering Tasks](http://richardknop.github.io/machinery/#registering-tasks)\r\n    - [Signatures](http://richardknop.github.io/machinery/#signatures)\r\n    - [Supported Types](http://richardknop.github.io/machinery/#supported-types)\r\n    - [Sending Tasks](http://richardknop.github.io/machinery/#sending-tasks)\r\n    - [Keeping Results](http://richardknop.github.io/machinery/#keeping-results)\r\n- [Workflows](http://richardknop.github.io/machinery/#workflows)\r\n    - [Groups](http://richardknop.github.io/machinery/#groups)\r\n    - [Chords](http://richardknop.github.io/machinery/#chords)\r\n    - [Chains](http://richardknop.github.io/machinery/#chains)\r\n- [Development Setup](http://richardknop.github.io/machinery/#development-setup)\r\n\r\n## First Steps\r\n\r\nAdd the Machinery library to your $GOPATH/src:\r\n\r\n```\r\n$ go get github.com/RichardKnop/machinery\r\n```\r\n\r\nInstall dependencies:\r\n\r\n```\r\n$ make deps\r\n```\r\n\r\nFirst, you will need to define some tasks. Look at sample tasks in `_examples/tasks/tasks.go` to see few examples.\r\n\r\nSecond, you will need to launch a worker process:\r\n\r\n```\r\n$ go run _examples/worker/worker.go\r\n```\r\n\r\n![Example worker][1]\r\n\r\nFinally, once you have a worker running and waiting for tasks to consume, send some tasks:\r\n\r\n```\r\n$ go run _examples/send/send.go\r\n```\r\n\r\nYou will be able to see the tasks being processed asynchronously by the worker:\r\n\r\n![Example worker receives tasks][2]\r\n\r\n## Configuration\r\n\r\nMachinery has several configuration options. Configuration is encapsulated by a `Config` struct and injected as a dependency to objects that need it.\r\n\r\n```go\r\ntype Config struct {\r\n\tBroker          string `yaml:\"broker\"`\r\n\tResultBackend   string `yaml:\"result_backend\"`\r\n\tResultsExpireIn int    `yaml:\"results_expire_in\"`\r\n\tExchange        string `yaml:\"exchange\"`\r\n\tExchangeType    string `yaml:\"exchange_type\"`\r\n\tDefaultQueue    string `yaml:\"default_queue\"`\r\n\tBindingKey      string `yaml:\"binding_key\"`\r\n}\r\n```\r\n\r\n### Broker\r\n\r\nA message broker. Currently supported brokers are:\r\n\r\n* AMQP (use AMQP URL such as `amqp://guest:guest@localhost:5672/`)\r\n* Redis (use Redis URL such as `redis://127.0.0.1:6379`)\r\n\r\n### ResultBackend\r\n\r\nResult backend to use for keeping task states and results.\r\n\r\nCurrently supported backends are:\r\n\r\n* Redis (use Redis URL such as `redis://127.0.0.1:6379`)\r\n* Memcache (use Memcache URL such as `memcache://10.0.0.1:11211,10.0.0.2:11211`)\r\n* AMQP (use AMQP URL such as `amqp://guest:guest@localhost:5672/`)\r\n\r\n> Keep in mind AMQP is not recommended as a result backend. See [Keeping Results](http://richardknop.github.io/machinery/#keeping-results)\r\n\r\n### ResultsExpireIn\r\n\r\nHow long to store task results for in seconds. Defaults to 3600 (1 hour).\r\n\r\n### Exchange\r\n\r\nExchange name, e.g. `machinery_exchange`. Only required for AMQP.\r\n\r\n### ExchangeType\r\n\r\nExchange type, e.g. `direct`. Only required for AMQP.\r\n\r\n### DefaultQueue\r\n\r\nDefault queue name, e.g. `machinery_tasks`.\r\n\r\n### BindingKey\r\n\r\nThe queue is bind to the exchange with this key, e.g. `machinery_task`. Only required for AMQP.\r\n\r\n## Server\r\n\r\nA Machinery library must be instantiated before use. The way this is done is by creating a `Server` instance. `Server` is a base object which stores Machinery configuration and registered tasks. E.g.:\r\n\r\n```go\r\n\r\nimport (\r\n    \"github.com/RichardKnop/machinery/v1/config\"\r\n    machinery \"github.com/RichardKnop/machinery/v1\"\r\n)\r\n\r\nvar cnf = config.Config{\r\n    Broker:        \"amqp://guest:guest@localhost:5672/\",\r\n    ResultBackend: \"amqp://guest:guest@localhost:5672/\",\r\n    Exchange:      \"machinery_exchange\",\r\n    ExchangeType:  \"direct\",\r\n    DefaultQueue:  \"machinery_tasks\",\r\n    BindingKey:    \"machinery_task\",\r\n}\r\n\r\nserver, err := machinery.NewServer(&cnf)\r\nif err != nil {\r\n    // do something with the error\r\n}\r\n```\r\n\r\n## Workers\r\n\r\nIn order to consume tasks, you need to have one or more workers running. All you need to run a worker is a `Server` instance with registered tasks. E.g.:\r\n\r\n```go\r\nworker := server.NewWorker(\"worker_name\")\r\nerr := worker.Launch()\r\nif err != nil {\r\n    // do something with the error\r\n}\r\n```\r\n\r\nEach worker will only consume registered tasks.\r\n\r\n## Tasks\r\n\r\nTasks are a building block of Machinery applications. A task is a function which defines what happens when a worker receives a message. Let's say we want to define tasks for adding and multiplying numbers:\r\n\r\n```go\r\nfunc Add(args ...int64) (int64, error) {\r\n    sum := int64(0)\r\n    for _, arg := range args {\r\n        sum += arg\r\n    }\r\n    return sum, nil\r\n}\r\n\r\nfunc Multiply(args ...int64) (int64, error) {\r\n    sum := int64(1)\r\n    for _, arg := range args {\r\n        sum *= arg\r\n    }\r\n    return sum, nil\r\n}\r\n```\r\n\r\n### Registering Tasks\r\n\r\nBefore your workers can consume a task, you need to register it with the server. This is done by assigning a task a unique name:\r\n\r\n```go\r\nserver.RegisterTasks(map[string]interface{}{\r\n    \"add\":      Add,\r\n    \"multiply\": Multiply,\r\n})\r\n```\r\n\r\nTask can also be registered one by one:\r\n\r\n```go\r\nserver.RegisterTask(\"add\", Add)\r\nserver.RegisterTask(\"multiply\", Multiply)\r\n```\r\n\r\nSimply put, when a worker receives a message like this:\r\n\r\n```json\r\n{\r\n    \"UUID\": \"48760a1a-8576-4536-973b-da09048c2ac5\",\r\n    \"Name\": \"add\",\r\n    \"RoutingKey\": \"\",\r\n    \"GroupUUID\": \"\",\r\n    \"GroupTaskCount\": 0,\r\n    \"Args\": [\r\n        {\r\n            \"Type\": \"int64\",\r\n            \"Value\": 1,\r\n        },\r\n        {\r\n            \"Type\": \"int64\",\r\n            \"Value\": 1,\r\n        }\r\n    ],\r\n    \"Immutable\": false,\r\n    \"OnSuccess\": null,\r\n    \"OnError\": null,\r\n    \"ChordCallback\": null\r\n}\r\n```\r\n\r\nIt will call Add(1, 1). Each task should return an error as well so we can handle failures.\r\n\r\nIdeally, tasks should be idempotent which means there will be no unintended consequences when a task is called multiple times with the same arguments.\r\n\r\n### Signatures\r\n\r\nA signature wraps calling arguments, execution options (such as immutability) and success/error callbacks of a task so it can be sent across the wire to workers. Task signatures implement a simple interface:\r\n\r\n```go\r\ntype TaskArg struct {\r\n    Type  string\r\n    Value interface{}\r\n}\r\n\r\ntype TaskSignature struct {\r\n    UUID           string\r\n    Name           string\r\n    RoutingKey     string\r\n    GroupUUID      string\r\n    GroupTaskCount int\r\n    Args           []TaskArg\r\n    Immutable      bool\r\n    OnSuccess      []*TaskSignature\r\n    OnError        []*TaskSignature\r\n    ChordCallback  *TaskSignature\r\n}\r\n```\r\n\r\n`UUID` is a unique ID of a task. You can either set it yourself or it will be automatically generated.\r\n\r\n`Name` is the unique task name by which it is registered against a Server instance.\r\n\r\n`RoutingKey` is used for routing a task to correct queue. If you leave it empty, the default behaviour will be to set it to the default queue's binding key for direct exchange type and to the default queue name for other exchange types.\r\n\r\n`GroupUUID`, GroupTaskCount are useful for creating groups of tasks.\r\n\r\n`Args` is a list of arguments that will be passed to the task when it is executed by a worker.\r\n\r\n`Immutable` is a flag which defines whether a result of the executed task can be modified or not. This is important with `OnSuccess` callbacks. Immutable task will not pass its result to its success callbacks while a mutable task will prepend its result to args sent to callback tasks. Long story short, set Immutable to false if you want to pass result of the first task in a chain to the second task.\r\n\r\n`OnSuccess` defines tasks which will be called after the task has executed successfully. It is a slice of task signature structs.\r\n\r\n`OnError` defines tasks which will be called after the task execution fails. The first argument passed to error callbacks will be the error returned from the failed task.\r\n\r\n`ChordCallback` is used to create a callback to a group of tasks.\r\n\r\n### Supported Types\r\n\r\nMachinery encodes tasks to JSON before sending them to the broker. Task results are also stored in the backend as JSON encoded strings. Therefor only types with native JSON representation can be supported. Currently supported types are:\r\n\r\n* `bool`\r\n* `int`\r\n* `int8`\r\n* `int16`\r\n* `int32`\r\n* `int64`\r\n* `unint`\r\n* `uint8`\r\n* `uint16`\r\n* `uint32`\r\n* `uint64`\r\n* `float32`\r\n* `float64`\r\n* `string`\r\n\r\n### Sending Tasks\r\n\r\nTasks can be called by passing an instance of `TaskSignature` to an `Server` instance. E.g:\r\n\r\n```go\r\nimport \"github.com/RichardKnop/machinery/v1/signatures\"\r\n\r\ntask := signatures.TaskSignature{\r\n    Name: \"add\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n    },\r\n}\r\n\r\nasyncResult, err := server.SendTask(&task1)\r\nif err != nil {\r\n    // failed to send the task\r\n    // do something with the error\r\n}\r\n```\r\n\r\n### Keeping Results\r\n\r\nIf you configure a result backend, the task states and results will be persisted. Possible states:\r\n\r\n```go\r\nconst (\r\n    PendingState  = \"PENDING\"\r\n    ReceivedState = \"RECEIVED\"\r\n    StartedState  = \"STARTED\"\r\n    SuccessState  = \"SUCCESS\"\r\n    FailureState  = \"FAILURE\"\r\n)\r\n```\r\n\r\n> When using AMQP as a result backend, task states will be persisted in separate queues for each task. Although RabbitMQ can scale up to thousands of queues, it is strongly advised to use a better suited result backend (e.g. Memcache) when you are expecting to run a large number of parallel tasks.\r\n\r\n```go\r\ntype TaskResult struct {\r\n    Type  string\r\n    Value interface{}\r\n}\r\n\r\ntype TaskState struct {\r\n    TaskUUID string\r\n    State    string\r\n    Result   *TaskResult\r\n    Error    string\r\n}\r\n\r\ntype GroupMeta struct {\r\n    GroupUUID string\r\n    TaskUUIDs []string\r\n}\r\n```\r\n\r\n`TaskResult` represents a return value of a processed task.\r\n\r\n`TaskState` struct will be serialised and stored every time a task state changes.\r\n\r\n`GroupMeta` stores useful metadata about tasks within the same group. E.g. UUIDs of all tasks which are used in order to check if all tasks completed successfully or not and thus whether to trigger chord callback.\r\n\r\n`AsyncResult` object allows you to check for the state of a task:\r\n\r\n```go\r\ntaskState := asyncResult.GetState()\r\nfmt.Printf(\"Current state of %v task is:\\n\", taskState.TaskUUID)\r\nfmt.Println(taskState.State)\r\n```\r\n\r\nThere are couple of convenient me methods to inspect the task status:\r\n\r\n```go\r\nasyncResult.GetState().IsCompleted()\r\nasyncResult.GetState().IsSuccess()\r\nasyncResult.GetState().IsFailure()\r\n```\r\n\r\nYou can also do a synchronous blocking call to wait for a task result:\r\n\r\n```go\r\nresult, err := asyncResult.Get()\r\nif err != nil {\r\n    // getting result of a task failed\r\n    // do something with the error\r\n}\r\nfmt.Println(result.Interface())\r\n```\r\n\r\n## Workflows\r\n\r\nRunning a single asynchronous task is fine but often you will want to design a workflow of tasks to be executed in an orchestrated way. There are couple of useful functions to help you design workflows.\r\n\r\n### Groups\r\n\r\n`Group` is a set of tasks which will be executed in parallel, independent of each other. E.g.:\r\n\r\n```go\r\nimport (\r\n    \"github.com/RichardKnop/machinery/v1/signatures\"\r\n    machinery \"github.com/RichardKnop/machinery/v1\"\r\n)\r\n\r\ntask1 := signatures.TaskSignature{\r\n    Name: \"add\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n    },\r\n}\r\n\r\ntask2 := signatures.TaskSignature{\r\n    Name: \"add\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 5,\r\n        },\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 5,\r\n        },\r\n    },\r\n}\r\n\r\ngroup := machinery.NewGroup(&task1, &task2)\r\nasyncResults, err := server.SendGroup(group)\r\nif err != nil {\r\n    // failed to send the group\r\n    // do something with the error\r\n}\r\n```\r\n\r\n`SendGroup` returns a slice of `AsyncResult` objects. So you can do a blocking call and wait for the result of groups tasks:\r\n\r\n```go\r\nfor _, asyncResult := range asyncResults {\r\n    result, err := asyncResult.Get()\r\n    if err != nil {\r\n        // getting result of a task failed\r\n        // do something with the error\r\n    }\r\n    fmt.Println(result.Interface())\r\n}\r\n```\r\n\r\n### Chords\r\n\r\n`Chord` allows you to define a callback to be executed after all tasks in a group finished processing, e.g.:\r\n\r\n```go\r\nimport (\r\n    \"github.com/RichardKnop/machinery/v1/signatures\"\r\n    machinery \"github.com/RichardKnop/machinery/v1\"\r\n)\r\n\r\ntask1 := signatures.TaskSignature{\r\n    Name: \"add\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n    },\r\n}\r\n\r\ntask2 := signatures.TaskSignature{\r\n    Name: \"add\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 5,\r\n        },\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 5,\r\n        },\r\n    },\r\n}\r\n\r\ntask3 := signatures.TaskSignature{\r\n    Name: \"multiply\",\r\n}\r\n\r\ngroup := machinery.NewGroup(&task1, &task2)\r\nchord := machinery.NewChord(group, &task3)\r\nchordAsyncResult, err := server.SendChord(chord)\r\nif err != nil {\r\n    // failed to send the chord\r\n    // do something with the error\r\n}\r\n```\r\n\r\nThe above example execute task1 and task2 in parallel, aggregate their results and pass them to task3. Therefor what would end up happening is:\r\n\r\n```\r\nmultiply(add(1, 1), add(5, 5))\r\n```\r\n\r\nMore explicitely:\r\n\r\n```\r\n(1 + 1) * (5 + 5) = 2 * 10 = 20\r\n```\r\n\r\n`SendChord` returns `ChordAsyncResult` which follows AsyncResult's interface. So you can do a blocking call and wait for the result of the callback:\r\n\r\n```go\r\nresult, err := chordAsyncResult.Get()\r\nif err != nil {\r\n    // getting result of a chord failed\r\n    // do something with the error\r\n}\r\nfmt.Println(result.Interface())\r\n```\r\n\r\n### Chains\r\n\r\n`Chain` is simply a set of tasks which will be executed one by one, each successful task triggering the next task in the chain. E.g.:\r\n\r\n```go\r\nimport (\r\n    \"github.com/RichardKnop/machinery/v1/signatures\"\r\n    machinery \"github.com/RichardKnop/machinery/v1\"\r\n)\r\n\r\ntask1 := signatures.TaskSignature{\r\n    Name: \"add\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 1,\r\n        },\r\n    },\r\n}\r\n\r\ntask2 := signatures.TaskSignature{\r\n    Name: \"add\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 5,\r\n        },\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 5,\r\n        },\r\n    },\r\n}\r\n\r\ntask3 := signatures.TaskSignature{\r\n    Name: \"multiply\",\r\n    Args: []signatures.TaskArg{\r\n        signatures.TaskArg{\r\n            Type:  \"int64\",\r\n            Value: 4,\r\n        },\r\n    },\r\n}\r\n\r\nchain := machinery.NewChain(&task1, &task2, &task3)\r\nchainAsyncResult, err := server.SendChain(chain)\r\nif err != nil {\r\n    // failed to send the chain\r\n    // do something with the error\r\n}\r\n```\r\n\r\nThe above example execute task1, then task2 and then task3, passing result of each task to the next task in the chain. Therefor what would end up happening is:\r\n\r\n```\r\nmultiply(add(add(1, 1), 5, 5), 4)\r\n```\r\n\r\nMore explicitely:\r\n\r\n```\r\n((1 + 1) + (5 + 5)) * 4 = 12 * 4 = 48\r\n```\r\n\r\n`SendChain` returns `ChainAsyncResult` which follows AsyncResult's interface. So you can do a blocking call and wait for the result of the whole chain:\r\n\r\n```go\r\nresult, err := chainAsyncResult.Get()\r\nif err != nil {\r\n    // getting result of a chain failed\r\n    // do something with the error\r\n}\r\nfmt.Println(result.Interface())\r\n```\r\n\r\n## Development Setup\r\n\r\nFirst, there are several requirements:\r\n\r\n- RabbitMQ\r\n- Go\r\n- Memcached (optional)\r\n\r\nOn OS X systems, you can install them using Homebrew:\r\n\r\n```\r\n$ brew install rabbitmq\r\n$ brew install redis\r\n$ brew install memcached\r\n$ brew install go\r\n```\r\n\r\nThen get all Machinery dependencies.\r\n\r\n```\r\n$ make deps\r\n```\r\n\r\n### Tests\r\n\r\n```\r\n$ make test\r\n```\r\n\r\nIn order to enable integration tests, you will need to export few environment variables:\r\n\r\n```\r\n$ export AMQP_URL=amqp://guest:guest@localhost:5672/\r\n$ export MEMCACHE_URL=127.0.0.1:11211\r\n$ export REDIS_URL=127.0.0.1:6379\r\n```\r\n\r\nI recommend to run the integration tests when making changes to the code. Due to Machinery being composed of several parts (worker, client) which run independently of each other, integration tests are important to verify everything works as expected.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}